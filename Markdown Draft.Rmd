---
title: "Dissertation HMM"
output: html_document
---

```{r setup, include=TRUE}
#Loaded Libraries
library(sp)        # Used for mapping
library(rgdal)     # Used for mapping
library(tidyverse) # Data Manipulation
library(readxl)    # Read excel tables
library(MASS)
library(moveHMM)  # Track spatial data and fit HMMs
library(caret)    # make conf.matrices
library(parallel) # parallel computing
library(ggplot2)  # data visualisation
library(gridExtra)
```

### Load Data

The column types are set accordingly, while others are skipped.

```{r load chickrearing 2011 data}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Data")


# Read Chick rearing excel file 2011

chk11 = read_excel("Coquet_2011_chickrearing_Tern_Tracks.xlsx", sheet = 1,
                   col_types = c("date", # Date column
                                 "skip", # skip colony
                                 "text", # Species column
                                 "numeric", # Track ID
                                 "skip","skip","skip", # skip HR MIN SEC
                                 "numeric","text",     # TSECS & CONTBEH
                                 "skip","skip",  # INSTANTBEH, FORAGESUC,
                                 "skip","skip", # PREYSIZE, PREYSPECIES
                                 "skip","skip",   # PREYFATE, NOTES
                                 "numeric","numeric", # BGNX, BGNY
                                 "numeric", "numeric", # LATITUDE, LONGITUDE
                                 "numeric","numeric", #DISTKM, DIST2COL
                                 "numeric","numeric" # BRG2COL, COMPLETE
                                 )
)

# turn contbeh to factor 
chk11$CONTBEH = as.factor(chk11$CONTBEH)

# rename TRACKID to ID
chk11 = chk11 %>%
  rename(
    ID = TRACKID
  )

#chk11 = chk11[order(chk11$ID,chk11$DATE,chk11$TSECS),]
```

```{r load chichrearing 2010 data}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Data")
chk10 = read_excel("Coquet_2010_chickrearing_Tern_Tracks.xlsx", sheet = 1,
                   col_types = c("date", # Date column
                                 "skip", # skip colony
                                 "text", # Species column
                                 "numeric", # Track ID
                                 "skip","skip","skip", # skip HR MIN SEC
                                 "numeric","text",     # TSECS & CONTBEH
                                 "skip","skip",  # INSTANTBEH, FORAGESUC,
                                 "skip","skip", # PREYSIZE, PREYSPECIES
                                 "skip","skip",   # PREYFATE, NOTES
                                 "numeric","numeric", # BGNX, BGNY
                                 "numeric", "numeric", # LATITUDE, LONGITUDE
                                 "numeric","numeric", #DISTKM, DIST2COL
                                 "numeric","numeric" # BRG2COL, COMPLETE
                   )
)
```

### Exploratory Data Analysis

\
A function that removes the "END" and "End" states is defined at this point and will be used in the validation and exploratory data analysis parts.\
```{r revise prpData}
# Removes End and End continuous statuses from prepData object

revise = function(df){
  
  new_df = df %>%
    filter(df$CONTBEH != "END" & df$CONTBEH != "End")
  
  return(new_df)
}
```

```{r EDA}
plot1 = ggplot(revise(chk11 %>% filter(SPECIES != "Common/Arctic")), aes(x=SPECIES, y = DIST2COL, fill = CONTBEH)) +
  geom_boxplot() + ggtitle("2011") + xlab("")
plot2 = ggplot(revise(chk10 %>% filter(SPECIES != "Common/Arctic")) %>% filter(CONTBEH != "REST"), aes(x=SPECIES, y = DIST2COL, fill = CONTBEH)) +
  geom_boxplot() + ggtitle("2010") 
grid.arrange(plot1,plot2)
```



```{r select libraries}

# copy dataset

chk11_cl = chk11 

# Save species names
speciesnames = unique(chk11_cl$SPECIES)
```
\
We will split the initial dataframe to sub-datasets per species. A function
is defined below that serves this specific reason.\ 
```{r function get_df}
get_df = function(df, species){
  
  ## Input:
  
  # df: dataframe to be filtered
  # species: species to be subsetted from df
  
  ## Output:
  
  # new_df: new dataframe containing examined species 
  
  species = enquo(species)
  
  # Simple function to extract species 
    new_df = df %>%
            filter(SPECIES == !!species) %>%
            dplyr::select(-SPECIES)
    
    return(as.data.frame(new_df))
}
```

```{r get dfs by species}
# dataframe by species - 2011 chickrearing

chk11.arc = get_df(chk11_cl,speciesnames[1]) # arctic

chk11.sand = get_df(chk11_cl,speciesnames[2]) # sandwich

chk11.comm = get_df(chk11_cl, speciesnames[3]) # common

# common/arct - unsure (will not be used in the analysis)

chk11.rose = get_df(chk11_cl, speciesnames[5]) # roseate
```


### Arctic
\
#### Models and Plots
```{r prepData arctic}
arc11.prepdata = prepData(chk11.arc, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r prepData arctic revised}
arc11.prepdata_revised =  revise(arc11.prepdata)

# Ensure that function worked as intented
unique(arc11.prepdata_revised$CONTBEH)
```
\
The histograms will be evaluated in order to define starting values. It seems that the histograms for the revised do not differ much (only 49 values were removed in the arctic 2011 case). Therefore picking similar starting values for both fitHMM instances is expected to produce the same optimization result. \
```{r plot prepdata differences}
#Check differences between dataframes -step
par(mfrow= c(2,2))
hist(arc11.prepdata$step, breaks = seq(0,0.019, l = 30), xlab = "Step" , main = "Original Dataframe")
hist(arc11.prepdata_revised$step, breaks = seq(0,0.019, l = 30), xlab = "Step", main = "End status removed")


hist(arc11.prepdata$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
hist(arc11.prepdata_revised$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
```
It is apparent that removing End & END continuous behaviours plays no major role in the analysis.

\
Basic model fitting using whole dataset.\

```{r fit basic}
# 4 States for HMM
nbStates = 2

# default Initial Values for distributions
beta0 = NULL
delta0 = NULL

formula = ~1

# Distributions used
stepDist = "gamma"
angleDist = "vm"

angleMean = NULL
stationary = FALSE

# propotion of zero steps. To be used for mass at 0    
zerostepprop = length(which(arc11.prepdata == 0))/nrow(arc11.prepdata) # = 0.6139

mu0 = c(0.003,0.015)
sigma0 = c(0.005,0.005)
zeromass0 = c(zerostepprop,0.1)
stepPar0 = c(mu0, sigma0, zeromass0)

angleMean0 = c(0,0)
kappa0 = c(1,1)
anglePar0 = c(angleMean0,kappa0)

arc11_basic_m = fitHMM(data = arc11.prepdata, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot basic}
#par(mfrow = c(1,2))
plot(arc11_basic_m, ask = F, plotCI = TRUE, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
Fitting on a revised dataset, with "End" and "END" states being removed.\

```{r fit revised}
# Fitting with no END and End
arc11_revised_m = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot revised}
plot(arc11_revised_m,plotCI = T, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
\
It has been concluded that adding more variables worsens model performance. Fitted states seem less sensible as well by using this model.\
```{r fit additional models}
disthmm = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = ~ DIST2COL + BRG2COL + DISTKM + TSECS)
```
\
```{r plot additional models}
plot(disthmm, ask = F, plotTracks = F)
```

\ 
The AIC values will ensure that we have chosen the correct model (~1) for the analysis. As it will be shown later by the confusion matrices, the accurracy percentages between the whole and revised prepData objects will be close.\
\
```{r AIC}
AIC(arc11_basic_m, arc11_revised_m, disthmm)
```
\
The following function helps with running multiple iterations of the maximization process with randomized initial values. The likelihood will be evaluated to ensure model has converged. The "parallel" package is also used and will assist by providing a lower computation time. \
\
```{r fit experiment function}

fit_experiment = function(str_obj,obj){


#Inputs:
#     str_obj : string name of dataframe we want to fit
#     obj: prepData actual object of dataframe we want to fit

#Output:
#     model_parallel: list of 5 fitted models

  
#Seed set outside iteration for reproducible results
set.seed(1)

# 5 iterations of the maximisation process will be used
n_iter = 5

ncores = detectCores() - 1
cl = makeCluster(getOption("cl.cores",ncores))

clusterExport(cl, list(str_obj,"fitHMM"))

allPar0 = lapply(as.list(1:n_iter), function(x){
  
  
   stepMean0 = runif(2,
                    min = c(0.002,0.008),
                    max = c(0.005,0.015)
  )
  stepSD0 = runif(2,
                    min = c(0.001,0.001),
                    max = c(0.001,0.003)
  )
  angleMean0 = c(0,0)
  angleConc0 = runif(2,
                    min = c(0.05,1),
                    max = c(0.5,2)
  )
  
  steppar0_f = c(stepMean0, stepSD0,zeromass0)
  anglePar0_f = c(angleMean0,angleConc0)
    
  return(list(step = steppar0_f, angle = anglePar0_f))
})

# parallel computing
model_parallel = parLapply(cl = cl, X = allPar0, fun = function(par0) {

     m <- fitHMM(data = obj, nbStates = 2, stepPar0 = par0$step,
anglePar0 = par0$angle)

    return(m)
              }
    )


return(model_parallel)
}
```
\
Call function.
\
```{r parallel arcic}
arctic_parallel_m = fit_experiment("arc11.prepdata_revised", arc11.prepdata_revised)
```

\
All values depict the same likelihood for ~1 function. Therefore the likelihood has been maximised adequately.
```{r print likelihoods arctic}
unlist(lapply(arctic_parallel_m, function(m) m$mod$minimum))
```

#### Confusion Matrices
\
As shown by the histograms below, Transit Search (TS) along with direct flight (DF) are described by higher flight speed and low turns, something that is captured by State 2. On the other hand, Active search (AS) is quite the opposite and will be recoded as state 1. The confusion matrices are given below for all models.\
```{r 2 states histogram}
par(mfrow = c(2,2))
hist(arc11.prepdata_revised$step[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,breaks = 55 , xlab = "Step", main = "Arctic - TS & DF")
hist(arc11.prepdata_revised$step[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,breaks = 55 , xlab = "Step", main = "Arctic - AS")
hist(arc11.prepdata_revised$angle[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = "")
hist(arc11.prepdata_revised$angle[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = "")
```

```{r confusion matrix function}
confmatrx = function(model, model_data){
  
  # Function that saves model states,
  # transforms model data and prints caret
  # elements
  
  ## Input:
  #
  # model: moveHMM object to be used in the viterbi function
  # data: actual observations for evaluation
  #
  # Output:
  #
  # confrevised: ConfusionMatrix object from the package caret

  states = viterbi(model) %>% as.factor
  recoded = model_data$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor()

  confrevised = caret:: confusionMatrix(states,recoded)

return(confrevised)
}
```
\
A custom function will be implemented to create heatmaps from each confusion matrix.\
\

```{r heatmap function}

heat_map_custom = function(matrixobject,str, showleg = T, size = 3, x = 0.7, y = 0.2, xlab = "Reference", ylab = "Prediction"){
  
  
  # Custom function that plots heatmaps and prints frequencies.
  #### Inputs: 
  # 
  # matrixobject: caret object from which table will be extracted
  # str: string to be used on title
  # showleg: True/False variable, whether to print legend or not
  # size: size of text underneath plot
  # x, y = coordinates of printed text
  # xlab, ylab = labels of x and y axis
  #
  ### Outputs:
  #
  # Heatmap plot that describes model acurracy
  
  
ggplot(as.data.frame(matrixobject$table), aes(x=Reference,y=Prediction, fill = Freq/sum(Freq))) + geom_tile(show.legend = showleg) + theme_bw() + 
    theme(axis.text = element_text(size = 8),
          axis.title = element_text(size = 10)) + 
    xlab(xlab) + ylab(ylab) + 
    ggtitle(paste(str))+
   scale_fill_distiller(palette = "Greens") + 
   geom_text(aes(label= paste(100*round(Freq/sum(Freq),4),"%"))) + 
    guides(fill = guide_legend(title = "Accurracy"))+
    # Print acurracy of model extracted by matrix object
    annotate("text", x=x,y = y, label = paste("Overall Acurracy:", 100*as.numeric(round(matrixobject$overall[1],4)),"%" ) , size = size)+
    coord_cartesian(ylim = c(1,2),clip="off")
}
```

```{r confusion matrix revised}
conf_arct_revised = confmatrx(arc11_revised_m,arc11.prepdata_revised)
conf_arct_revised
```
\ 
```{r arctic plot heatmap for revised model}
heat_arctic = heat_map_custom(conf_arct_revised,"Arctic",showleg = F, xlab = "", x = 0.9, y =0.015, size = 2.5)
heat_arctic
```


```{r experiment}
hist(arc11.prepdata_revised$step[which((viterbi(arc11_revised_m)) !=  ((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2))], breaks = 60)

```



The additional variables produce higher accuracy but also fail to adequately predict type 1 cases. The analysis indicates that ~1 produces the best model.\
```{r conf matrix additional}
conf_arc_add = confmatrx(disthmm, arc11.prepdata_revised)

heat_map_custom(conf_arc_add, "Arctic 2011 -Additional Models")
```

### Sandwich
\
The analysis will be the same as the previous section\
\
#### Data Manipulation

```{r sandwich prepdata}
sand11.prepdata = prepData(chk11.sand, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```
```{r sandwich plots and revised}
sand11.prepdata_revised = revise(sand11.prepdata)

# Remove outlier 

sand11.prepdata_revised = sand11.prepdata_revised[-which.max(sand11.prepdata_revised$step),]

par(mfrow=c(1,2))
hist(sand11.prepdata_revised$step, xlab = "Step")
hist(sand11.prepdata_revised$angle, xlab = "Angle")
```
\
#### Fit and Plots
As previously we will run a parallel experiment to evaluate convergence.\

```{r sand fit parallel}
sand_parallel_m = fit_experiment("sand11.prepdata_revised",sand11.prepdata_revised)
```

```{r print likelihoods sand}
# Print likelihoods
unlist(lapply(sand_parallel_m, function(m) m$mod$minimum))
```
\
Convergence is reached based on the above results.
```{r sand fit}
sand_fit_m = fitHMM(data = sand11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```
\
```{r sand plot}
plot(sand_fit_m, ask = F,  plotTracks = F)
```
#### Confusion Matrix

```{r sandwich confusion matrix}
conf_sand = confmatrx(sand_fit_m,sand11.prepdata_revised)

heat_sand = heat_map_custom(conf_sand, "Sandwich", size = 2.5, F, x = 0.9, y =0.015, xlab = "", ylab = "")
```
### Common

#### Data Manipulation
```{r common prepdata}
comm11.prepdata = prepData(chk11.comm, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r common revise & Plot}
comm11.prepdata_revised = revise(comm11.prepdata)

par(mfrow = c(1,2))
hist(comm11.prepdata_revised$step, seq(0,0.019,l=40))
hist(comm11.prepdata_revised$angle,seq(-pi,pi,l=40))
```
#### Fit and Plots
\

```{r common fit parallel}
common_parallel_m = fit_experiment("comm11.prepdata_revised",comm11.prepdata_revised)
```

```{r print likelihoods common}
# Print likelihoods
unlist(lapply(common_parallel_m, function(m) m$mod$minimum))
```
```{r common fit}
common_fit_m = fitHMM(data = comm11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot common}
plot(common_fit_m, ask = F, plotTracks = F)
```
```{r common confusion matrix}
conf_common = confmatrx(common_fit_m,comm11.prepdata_revised)

heat_common = heat_map_custom(conf_common, "Common", F, size = 2.5, x = 0.9, y =0.015)

```

### Roseate

#### Load Data

```{r rose prepdata}
rose11.prepdata = prepData(chk11.rose, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r rose prepdata revised & plot}
rose11.prepdata_revised = revise(rose11.prepdata)

par(mfrow = c(1,2))
hist(rose11.prepdata_revised$step, seq(0,0.020,l=40))
hist(rose11.prepdata_revised$angle,seq(-pi,pi,l=40))
```
#### Fit & Plots

```{r rose fit parallel}
rose_parallel_m = fit_experiment("rose11.prepdata_revised",rose11.prepdata_revised)
```

```{r print likelihoods rose}
# Print likelihoods
unlist(lapply(rose_parallel_m, function(m) m$mod$minimum))
```
\
Convergence is reached based on the above results.
```{r rose fit}
rose_fit_m = fitHMM(data = rose11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```
\
```{r rose plot}
plot(rose_fit_m, plotTracks = F, ask = F)
```
#### Confusion Matrix

```{r rose confusion matrix}
conf_rose = confmatrx(rose_fit_m,rose11.prepdata_revised)

heat_rose = heat_map_custom(conf_rose, "Roseate", x = 0.9, y =0.015, size = 2.5, showleg = F, ylab = "")
```

## Summarised Plots

```{r Steps per species}
arcticplot_step = ggplot(arc11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Arctic") + xlab("") + ylab("Step")

commplot_step = ggplot(comm11.prepdata_revised, aes(x = CONTBEH ,y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Common") + xlab("") + ylab("")

sandplot_step = ggplot(sand11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Sandwich") + ylab("Step")

roseplot_step = ggplot(rose11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Roseate") + ylab("")

step_per_species_2011 = grid.arrange(arcticplot_step,commplot_step,sandplot_step,roseplot_step, nrow = 2 , ncol = 2, top =  "Step")
```

```{r angle per species}
arcticplot_angle = ggplot(arc11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Arctic") + xlab("")

commplot_angle = ggplot(comm11.prepdata_revised %>% na.omit, aes(x = CONTBEH ,y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Common")

sandplot_angle = ggplot(sand11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Sandwich")

roseplot_angle = ggplot(rose11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Roseate")

angle_per_species_2011 = grid.arrange(arcticplot_angle,commplot_angle,sandplot_angle, roseplot_angle, nrow = 2 , ncol = 2, name = "Angle values per Behaviour", top = "Turning angles")
```

```{r summarised step plot}
grid.arrange(step_per_species_2011,angle_per_species_2011, ncol =2, top = "Movement Characteristics by species and continuous behaviour" )
```
```{r summarised confusion matrices}
grid.arrange(heat_arctic,heat_sand,heat_common,heat_rose, ncol = 2, nrow = 2, top = "Confusion Matrices per Species")
```
# Mapping 

\ 
In the mapping section, the relevant plots will be produced and functions will be defined./

```{r initialise mapping Coordinates}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Resources for Mapping")
uk<-readOGR("GBR_adm1.shp") 
ukgrid <- "+init=epsg:27700" 
uk_ukgrid <- spTransform(uk, ukgrid)
```

```{r map per ID}
ggplot() +
geom_polygon(data = uk_ukgrid, aes(x = long, y = lat, group = group), colour = "black", fill = NA) +
geom_point(data=arc11.prepdata_revised %>% filter(ID == 59), aes(x=BNGX,y=BNGY, color = CONTBEH))+coord_fixed(ratio = 1, xlim = c(425000,430000+5000), ylim = c(600000, 600000+10000) )
```

```{r plotcomplete function}
plotcomplete = function(df, complete = 1, str = "Title", legendshow = F){
  #
  #
  # Function that plots behavioural tracks of all birds based on complete/incomplete status
  #
  #### Inputs:
  #
  # df: dataframe from which coordinates will be extracted
  # complete:  1 for complete tracking, 0 for incomplete
  # str: string to be used in title
  # legendshow: whether to show legend or not
  #
  #### Output:
  #
  # ggplot tracks per tern, categorised by continuous behavior
  
  
ggplot() +
geom_polygon(data = uk_ukgrid, aes(x = long, y = lat, group = group), colour = "black", fill = NA) +
geom_point(data=df %>% filter(Complete == complete),show.legend = legendshow, 
           aes(x=BNGX,y=BNGY, color = CONTBEH) )  +
    
    coord_fixed(ratio = 1.5, 
                    xlim = c(df %>% filter(Complete == complete) %>% pull(BNGX) %>% min() - 
                              df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() ,
                             df %>% filter(Complete == complete) %>% pull(BNGX) %>% max()) +
                             df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() , 
                    ylim = c(df %>% filter(Complete == complete) %>% pull(BNGY) %>% min() - 
                             df%>% filter(Complete == complete) %>% pull(BNGY) %>% sd(), 
                             df %>% filter(Complete == complete) %>% pull(BNGY) %>% max()) + 
                             df %>% filter(Complete == complete) %>% pull(BNGY) %>% sd() 
                    )  +
    ggtitle(str) +
    theme(legend.position = "bottom")
}
```
```{r plotboth function}
plotcomplete_incomplete = function(df, title = "Title"){
  #
  #
  # Plots both states by using the function "plotcomplete" 
  #
  # Returns a grid-plot with both Complete-Incomplete plots combined
  
  df_com = suppressMessages(plotcomplete(df, str = "Complete", complete = 1, legendshow = F))
  df_incom = suppressMessages(plotcomplete(df, str = "Incomplete", complete = 0, legendshow = T))
  grid = grid.arrange(df_com, df_incom, ncol = 2, top = title)
  return(grid)
}
```

```{r plotalltracks}
plotalltracks = function(df_arctic, df_sand, df_common, df_rose){
  
  #
  # Takes 4 dataframes as input (1 per species) and returns the 
  # corresponding grids by using the function "plotcomplete_incomplete"
  #
  
grid1 = plotcomplete_incomplete(df_arctic, title = "Arctic")
grid2 = plotcomplete_incomplete(df_sand, title = "Sandwich")
grid3 = plotcomplete_incomplete(df_common, title = "Common")
grid4 = plotcomplete_incomplete(df_rose, title = "Roseate")
}
```
```{r call plot all tracks function}
plotalltracks(arc11.prepdata_revised, sand11.prepdata_revised,comm11.prepdata_revised,rose11.prepdata_revised)
```