---
title: "Dissertation HMM"
output: html_document
---

```{r setup, include=TRUE}
#Loaded Libraries
library(sp)        # Used for mapping
library(rgdal)     # Used for mapping
library(tidyverse) # Data Manipulation
library(readxl)    # Read excel tables
library(MASS)
library(JointAI)
library(moveHMM)  # Track spatial data and fit HMMs
library(caret)    # make conf.matrices
library(parallel) # parallel computing
library(ggplot2)  # data visualisation
library(gridExtra)
```

### Load Data

The column types are set accordingly, while others are skipped.

```{r load chickrearing 2011 data}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Data")


# Read Chick rearing excel file 2011

chk11 = read_excel("Coquet_2011_chickrearing_Tern_Tracks.xlsx", sheet = 1,
                   col_types = c("date", # Date column
                                 "skip", # skip colony
                                 "text", # Species column
                                 "numeric", # Track ID
                                 "skip","skip","skip", # skip HR MIN SEC
                                 "numeric","text",     # TSECS & CONTBEH
                                 "text","text",  # INSTANTBEH, FORAGESUC,
                                 "text","text", # PREYSIZE, PREYSPECIES
                                 "text","text",   # PREYFATE, NOTES
                                 "numeric","numeric", # BGNX, BGNY
                                 "numeric", "numeric", # LATITUDE, LONGITUDE
                                 "numeric","numeric", #DISTKM, DIST2COL
                                 "numeric","numeric" # BRG2COL, COMPLETE
                                 )
)

# turn contbeh to factor 
chk11$CONTBEH = as.factor(chk11$CONTBEH)

# rename TRACKID to ID
chk11 = chk11 %>%
  rename(
    ID = TRACKID
  )

#chk11 = chk11[order(chk11$ID,chk11$DATE,chk11$TSECS),]
```

```{r load chichrearing 2010 data}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Data")
chk10 = read_excel("Coquet_2010_chickrearing_Tern_Tracks.xlsx", sheet = 1,
                   col_types = c("date", # Date column
                                 "skip", # skip colony
                                 "text", # Species column
                                 "numeric", # Track ID
                                 "skip","skip","skip", # skip HR MIN SEC
                                 "numeric","text",     # TSECS & CONTBEH
                                 "text","text",  # INSTANTBEH, FORAGESUC,
                                 "text","text", # PREYSIZE, PREYSPECIES
                                 "text","text",   # PREYFATE, NOTES
                                 "numeric","numeric", # BGNX, BGNY
                                 "numeric", "numeric", # LATITUDE, LONGITUDE
                                 "numeric","numeric", #DISTKM, DIST2COL
                                 "numeric","numeric" # BRG2COL, COMPLETE
                   )
)
```

\
Firstly, the missingness plot is given in order to gain an understanding of which dataframe to use (2011 has much more many observations than the 2010 chickrearing one).\ 

```{r missing data}
par(mfrow = c(1,2))
md10 = md_pattern(chk10, pattern = F, c("black","red"))
md11 = md_pattern(chk11, pattern = F, c("black","red"))
grid.arrange(md10,md11, ncol = 2, top = "Missing Data Patterns in 2010 vs 2011 chickrearing seasons")
```
\
Secondly, the complete tracking ratio is also higher in the 2011 counterpart, as seen below. Besides the exploratory data analysis, the 2011 dataframe is thus preferred for the fitting procedure.
\
```{r complete ratios between dfs}
paste("complete ratio 2011:", round(sum(chk11$Complete)/nrow(chk11),3))
paste("complete ratio 2010:", round(sum(chk10$Complete)/nrow(chk10),3))
```

### Exploratory Data Analysis

\

A function that removes the "END" and "End" states is defined at this point and will be used in the validation and exploratory data analysis parts.\
```{r revise prpData}
# Removes End and End continuous statuses from prepData object

revise = function(df){
  
  new_df = df %>%
    filter(df$CONTBEH != "END" & df$CONTBEH != "End")
  
  return(new_df)
}
```

\
Continuous behaviour - tracking plots
\
```{r EDA Dist 2 Col}
plot1 = ggplot(revise(chk11 %>% filter(SPECIES != "Common/Arctic")), aes(x=SPECIES, y = DIST2COL, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("2011") + xlab("") + ylab("Dist to colony (m)")
plot2 = ggplot(revise(chk10 %>% filter(SPECIES != "Common/Arctic")) %>% filter(CONTBEH != "REST"), aes(x=SPECIES, y = DIST2COL, fill = CONTBEH)) +
  geom_boxplot(show.legend = T) + ggtitle("2010") + theme(legend.position = "bottom") + ylab("Dist to colony (m)") + 
  guides(fill=guide_legend(title="Cont. Behaviour"))
DIST2COL_plot = grid.arrange(plot1,plot2, top = "Continuous behaviour in relation to distance of tern from the colony")
```
Average distance of each observed behaviour from colony
```{r means DISTKM per behaviour}
paste("TS:",chk11 %>% filter(CONTBEH == "TS") %>% dplyr:: select(DIST2COL) %>% colMeans() %>% round(3))
paste("DF:", chk11 %>% filter(CONTBEH == "DF") %>% dplyr:: select(DIST2COL) %>% colMeans() %>% round(3))
paste("AS:",chk11 %>% filter(CONTBEH == "AS") %>% dplyr:: select(DIST2COL) %>% colMeans() %>% round(3))
```

```{r EDA Dist 2 KM}
plot1 = ggplot(revise(chk11 %>% filter(SPECIES != "Common/Arctic", DISTKM != max(DISTKM)) ), aes(x=SPECIES, y = DISTKM , fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("2011") + xlab("") + ylab("Dist to tern (km)")
plot2 = ggplot(revise(chk10 %>% filter(SPECIES != "Common/Arctic")) %>% filter(CONTBEH != "REST"), aes(x=SPECIES, y = DISTKM, fill = CONTBEH)) +
  geom_boxplot(show.legend = T) + ggtitle("2010") + theme(legend.position = "bottom") + ylab("Dist to tern (km)") + theme(legend.position = "bottom") + 
  guides(fill=guide_legend(title="Cont. Behaviour"))
DISTKM_plot = grid.arrange(plot1,plot2, top =  "Continuous behaviour in relation to distance of tern from the boat")
```
```{r behavioural plots per species}
ggplot(revise(chk10 %>% dplyr:: select(CONTBEH, PREYFATE, FORAGESUCC, SPECIES, Complete)) %>% filter(FORAGESUCC != 9, CONTBEH != "KP", CONTBEH != "REST") %>% na.omit())  + geom_bar(aes(x = FORAGESUCC, y = (..count..), fill = PREYFATE))
```


```{r select coiumns}

# copy dataset and select appropriate columns

chk11_cl = chk11 %>%  dplyr:: select(DATE,SPECIES,TRACKID,TSECS,CONTBEH,BNGX,BNGY,LATITUDE,LONGITUDE,DISTKM,DIST2COL,BRG2COL,Complete)

# Save species names
speciesnames = unique(chk11_cl$SPECIES)
```
\
We will split the initial dataframe to sub-datasets per species. A function
is defined below that serves this specific reason.\ 
```{r function get_df}
get_df = function(df, species){
  
  ## Input:
  
  # df: dataframe to be filtered
  # species: species to be subsetted from df
  
  ## Output:
  
  # new_df: new dataframe containing examined species 
  
  species = enquo(species)
  
  # Simple function to extract species 
    new_df = df %>%
            filter(SPECIES == !!species) %>%
            dplyr::select(-SPECIES)
    
    return(as.data.frame(new_df))
}
```

```{r get dfs by species}
# dataframe by species - 2011 chickrearing

chk11.arc = get_df(chk11_cl,speciesnames[1]) # arctic

chk11.sand = get_df(chk11_cl,speciesnames[2]) # sandwich

chk11.comm = get_df(chk11_cl, speciesnames[3]) # common

# common/arct - unsure (will not be used in the analysis)

chk11.rose = get_df(chk11_cl, speciesnames[5]) # roseate
```


### Arctic
\
#### Models and Plots
```{r prepData arctic}
arc11.prepdata = prepData(chk11.arc, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r prepData arctic revised}
arc11.prepdata_revised =  revise(arc11.prepdata)

# Ensure that function worked as intented
unique(arc11.prepdata_revised$CONTBEH)
```
\
The histograms will be evaluated in order to define starting values. It seems that the histograms for the revised do not differ much (only 49 values were removed in the arctic 2011 case). Therefore picking similar starting values for both fitHMM instances is expected to produce the same optimization result. \
```{r plot prepdata differences}
#Check differences between dataframes -step
par(mfrow= c(2,2))
hist(arc11.prepdata$step, breaks = seq(0,0.019, l = 30), xlab = "Step" , main = "Original Dataframe")
hist(arc11.prepdata_revised$step, breaks = seq(0,0.019, l = 30), xlab = "Step", main = "End status removed")


hist(arc11.prepdata$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
hist(arc11.prepdata_revised$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
```
It is apparent that removing End & END continuous behaviours plays no major role in the analysis.

\
Basic model fitting using whole dataset.\

```{r fit basic}
# 4 States for HMM
nbStates = 2

# default Initial Values for distributions
beta0 = NULL
delta0 = NULL

formula = ~1

# Distributions used
stepDist = "gamma"
angleDist = "vm"

angleMean = NULL
stationary = FALSE

# propotion of zero steps. To be used for mass at 0    
zerostepprop = length(which(arc11.prepdata == 0))/nrow(arc11.prepdata) # = 0.6139

mu0 = c(0.003,0.015)
sigma0 = c(0.005,0.005)
zeromass0 = c(zerostepprop,0.1)
stepPar0 = c(mu0, sigma0, zeromass0)

angleMean0 = c(0,0)
kappa0 = c(1,1)
anglePar0 = c(angleMean0,kappa0)

arc11_basic_m = fitHMM(data = arc11.prepdata, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula, stepDist = stepDist, angleDist = angleDist)
```

```{r plot basic}
#par(mfrow = c(1,2))
plot(arc11_basic_m, ask = F, plotCI = TRUE, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
Fitting on a revised dataset, with "End" and "END" states being removed.\

```{r fit revised}
# Fitting with no END and End
arc11_revised_m = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot revised}
plot(arc11_revised_m,ask = F,plotCI = T, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
\
It has been concluded that adding more variables worsens model performance. Fitted states seem less sensible as well by using this model.\
```{r fit additional models}
disthmm = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = ~ DIST2COL + BRG2COL + DISTKM + TSECS)
```
\
```{r plot additional models}
plot(disthmm, ask = F, plotTracks = F)
```

\ 
The AIC values will ensure that we have chosen the correct model (~1) for the analysis. As it will be shown later by the confusion matrices, the accurracy percentages between the whole and revised prepData objects will be close.\
\
```{r AIC}
AIC(arc11_basic_m, arc11_revised_m, disthmm)
```
\
The following function helps with running multiple iterations of the maximization process with randomized initial values. The likelihood will be evaluated to ensure model has converged. The "parallel" package is also used and will assist by providing a lower computation time. \
\
```{r fit experiment function}

fit_experiment = function(str_obj,obj){


#Inputs:
#     str_obj : string name of dataframe we want to fit
#     obj: prepData actual object of dataframe we want to fit

#Output:
#     model_parallel: list of 5 fitted models

  
#Seed set outside iteration for reproducible results
set.seed(1)

# 5 iterations of the maximisation process will be used
n_iter = 5

ncores = detectCores() - 1
cl = makeCluster(getOption("cl.cores",ncores))

clusterExport(cl, list(str_obj,"fitHMM"))

allPar0 = lapply(as.list(1:n_iter), function(x){
  
  
   stepMean0 = runif(2,
                    min = c(0.002,0.008),
                    max = c(0.005,0.015)
  )
  stepSD0 = runif(2,
                    min = c(0.001,0.001),
                    max = c(0.001,0.003)
  )
  angleMean0 = c(0,0)
  angleConc0 = runif(2,
                    min = c(0.05,1),
                    max = c(0.5,2)
  )
  
  steppar0_f = c(stepMean0, stepSD0,zeromass0)
  anglePar0_f = c(angleMean0,angleConc0)
    
  return(list(step = steppar0_f, angle = anglePar0_f))
})

# parallel computing
model_parallel = parLapply(cl = cl, X = allPar0, fun = function(par0) {

     m <- fitHMM(data = obj, nbStates = 2, stepPar0 = par0$step,
anglePar0 = par0$angle)

    return(m)
              }
    )


return(model_parallel)
}
```
\
Call function.
\
```{r parallel arcic}
arctic_parallel_m = fit_experiment("arc11.prepdata_revised", arc11.prepdata_revised)
```

\
All values depict the same likelihood for ~1 function. Therefore the likelihood has been maximised adequately.
```{r likelihood test}
likelihoodtest = function(modelparallel, modelfit, numericalapprox = 20){
  #
  #
  # Checks for approximation between paralell experiment and fitted values with
  # precision in numericalapprox decimals
  #
  ### Inputs:
  #
  # modelparallel: list object containing 5 fitted models
  # modelfit: moveHMM fited model
  # numericalapprox: number of decimals to be evaluated. Starts with a precision
  # of 20 decimals and moves to lower acurracy until  the condition is met
  # 
  #
  minvalue = (unlist(lapply(modelparallel, function(m) m$mod$minimum))) %>% min()
  
  check = F
  while (check == F){
    
    value_parallel = minvalue %>% round(numericalapprox)
    value_model =  modelfit$mod$minimum %>% round(numericalapprox)
   
     condition = value_parallel == value_model 
      
      
    
    if (condition == T){
      check = T
      print(paste("Convergence between parallel and model fit is reached with precision in",numericalapprox,"decimals"))
      print(paste("Parallel min Likelihood:",value_parallel,", Model Likelihood:",value_model))
    } else {
      numericalapprox = numericalapprox - 1
    }
  }
  
  
}

likelihoodtest(arctic_parallel_m, arc11_revised_m)
```

#### Confusion Matrices
\
As shown by the histograms below, Transit Search (TS) along with direct flight (DF) are described by higher flight speed and low turns, something that is captured by State 2. On the other hand, Active search (AS) is quite the opposite and will be recoded as state 1. The confusion matrices are given below for all models.\
```{r 2 states histogram}
analyse_histograms = function(df, title){
  #
  #
  # Inputs: 
  # df: dataframe to be used in plots
  # title: Species
  
hist(df$step[which((df$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,breaks = 55 , xlab = "Step", main = paste(title," - TS & DF"))
hist(df$step[which((df$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,breaks = 55 , xlab = "Step", main = paste(title," - AS"))
hist(df$angle[which((df$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = paste(title," - TS & DF"))
hist(df$angle[which((df$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = paste(title," - AS"))
}

par(mfrow = c(2,2))
analyse_histograms(arc11.prepdata_revised, title = "Arctic")
```


```{r confusion matrix function}
confmatrx = function(model, model_data){
  
  # Function that saves model states,
  # transforms model data and prints caret
  # elements
  
  ## Input:
  #
  # model: moveHMM object to be used in the viterbi function
  # data: actual observations for evaluation
  #
  # Output:
  #
  # confrevised: ConfusionMatrix object from the package caret

  states = viterbi(model) %>% as.factor
  recoded = model_data$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor()

  confrevised = caret:: confusionMatrix(states,recoded)

return(confrevised)
}
```
\
A custom function will be implemented to create heatmaps from each confusion matrix.\
\

```{r heatmap function}

heat_map_custom = function(matrixobject,str, showleg = T, size = 3, x = 0.7, y = 0.2, xlab = "Reference", ylab = "Prediction"){
  
  
  # Custom function that plots heatmaps and prints frequencies.
  #### Inputs: 
  # 
  # matrixobject: caret object from which table will be extracted
  # str: string to be used on title
  # showleg: True/False variable, whether to print legend or not
  # size: size of text underneath plot
  # x, y = coordinates of printed text
  # xlab, ylab = labels of x and y axis
  #
  ### Outputs:
  #
  # Heatmap plot that describes model acurracy
  
  
ggplot(as.data.frame(matrixobject$table), aes(x=Reference,y=Prediction, fill = Freq/sum(Freq))) + geom_tile(show.legend = showleg) + theme_bw() + 
    theme(axis.text = element_text(size = 8),
          axis.title = element_text(size = 10)) + 
    xlab(xlab) + ylab(ylab) + 
    ggtitle(paste(str))+
   scale_fill_distiller(palette = "Greens") + 
   geom_text(aes(label= paste(100*round(Freq/sum(Freq),4),"%"))) + 
    guides(fill = guide_legend(title = "Accurracy"))+
    # Print acurracy of model extracted by matrix object
    annotate("text", x=x,y = y, label = paste("Overall Acurracy:", 100*as.numeric(round(matrixobject$overall[1],4)),"%" ) , size = size)+
    coord_cartesian(ylim = c(1,2),clip="off")
}
```

```{r confusion matrix revised}
conf_arct_revised = confmatrx(arc11_revised_m,arc11.prepdata_revised)
conf_arct_revised
```
\ 
```{r arctic plot heatmap for revised model}
heat_arctic = heat_map_custom(conf_arct_revised,"Arctic",showleg = F, xlab = "", x = 0.9, y =0.015, size = 2.5)
heat_arctic
```


```{r experiment}
hist(arc11.prepdata_revised$step[which((viterbi(arc11_revised_m)) !=  ((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2))], breaks = 60)

```



The additional variables produce higher accuracy but also fail to adequately predict type 1 cases. The analysis indicates that ~1 produces the best model.\
```{r conf matrix additional}
conf_arc_add = confmatrx(disthmm, arc11.prepdata_revised)

heat_map_custom(conf_arc_add, "Arctic 2011 -Additional Models")
```

### Sandwich
\
The analysis will be the same as the previous section\
\
#### Data Manipulation

```{r sandwich prepdata}
sand11.prepdata = prepData(chk11.sand, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```
```{r sandwich plots and revised}
sand11.prepdata_revised = revise(sand11.prepdata)

# Remove outlier 

sand11.prepdata_revised = sand11.prepdata_revised[-which.max(sand11.prepdata_revised$step),]

par(mfrow=c(1,2))
hist(sand11.prepdata_revised$step, xlab = "Step")
hist(sand11.prepdata_revised$angle, xlab = "Angle")
```
\
#### Fit and Plots
As previously we will run a parallel experiment to evaluate convergence.\

```{r sand fit parallel}
sand_parallel_m = fit_experiment("sand11.prepdata_revised",sand11.prepdata_revised)
```

\

```{r sand fit}
sand_fit_m = fitHMM(data = sand11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```
\

Convergence is reached based on the above results.
```{r print likelihoods sand}
# Print likelihoods
likelihoodtest(sand_parallel_m,sand_fit_m)
```
\

```{r sand plot}
plot(sand_fit_m, ask = F,  plotTracks = F)
```
#### Confusion Matrix

```{r sandwich confusion matrix}
conf_sand = confmatrx(sand_fit_m,sand11.prepdata_revised)

heat_sand = heat_map_custom(conf_sand, "Sandwich", size = 2.5, F, x = 0.9, y =0.015, xlab = "", ylab = "")
```
### Common

#### Data Manipulation
```{r common prepdata}
comm11.prepdata = prepData(chk11.comm, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r common revise & Plot}
comm11.prepdata_revised = revise(comm11.prepdata)

par(mfrow = c(1,2))
hist(comm11.prepdata_revised$step, seq(0,0.019,l=40))
hist(comm11.prepdata_revised$angle,seq(-pi,pi,l=40))
```
#### Fit and Plots
\

```{r common fit parallel}
common_parallel_m = fit_experiment("comm11.prepdata_revised",comm11.prepdata_revised)
```

```{r common fit}
common_fit_m = fitHMM(data = comm11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r print likelihoods common}
# Print likelihoods
likelihoodtest(common_parallel_m,common_fit_m)
```
```{r plot common}
plot(common_fit_m, ask = F, plotTracks = F)
```
```{r common confusion matrix}
conf_common = confmatrx(common_fit_m,comm11.prepdata_revised)

heat_common = heat_map_custom(conf_common, "Common", F, size = 2.5, x = 0.9, y =0.015)

```

### Roseate

#### Load Data

```{r rose prepdata}
rose11.prepdata = prepData(chk11.rose, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r rose prepdata revised & plot}
rose11.prepdata_revised = revise(rose11.prepdata)

par(mfrow = c(1,2))
hist(rose11.prepdata_revised$step, seq(0,0.020,l=40))
hist(rose11.prepdata_revised$angle,seq(-pi,pi,l=40))
```
#### Fit & Plots

```{r rose fit parallel}
rose_parallel_m = fit_experiment("rose11.prepdata_revised",rose11.prepdata_revised)
```


\
Convergence is reached based on the above results.
```{r rose fit}
rose_fit_m = fitHMM(data = rose11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```
\
```{r print likelihoods rose}
# Print likelihoods
likelihoodtest(rose_parallel_m, rose_fit_m)
```
\
```{r rose plot}
plot(rose_fit_m, plotTracks = F, ask = F)
```
#### Confusion Matrix

```{r rose confusion matrix}
conf_rose = confmatrx(rose_fit_m,rose11.prepdata_revised)

heat_rose = heat_map_custom(conf_rose, "Roseate", x = 0.9, y =0.015, size = 2.5, showleg = F, ylab = "")
```

## Summarised Plots

#### Histograms of Step Lengths and Turning Angles

```{r analyse steps and turning angles}
par(mfrow = c(2,4))
analyse_histograms(arc11.prepdata_revised, title = "Arctic")
analyse_histograms(sand11.prepdata_revised, title = "Sandwich")
par(mfrow = c(2,4))
analyse_histograms(comm11.prepdata_revised, title = "Common")
analyse_histograms(rose11.prepdata_revised, title = "Roseate")
```

#### Boxplots of the above histograms

```{r Steps per species}
arcticplot_step = ggplot(arc11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Arctic") + xlab("") + ylab("Step-Length")

commplot_step = ggplot(comm11.prepdata_revised, aes(x = CONTBEH ,y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Common") + xlab("") + ylab("")

sandplot_step = ggplot(sand11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Sandwich") + ylab("Step-Length")

roseplot_step = ggplot(rose11.prepdata_revised, aes(x = CONTBEH, y = step, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Roseate") + ylab("")

step_per_species_2011 = grid.arrange(arcticplot_step,commplot_step,sandplot_step,roseplot_step, nrow = 2 , ncol = 2, top =  "Step-length")
```

```{r angle per species}
arcticplot_angle = ggplot(arc11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Arctic") + xlab("")

commplot_angle = ggplot(comm11.prepdata_revised %>% na.omit, aes(x = CONTBEH ,y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Common") + xlab("")

sandplot_angle = ggplot(sand11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Sandwich")

roseplot_angle = ggplot(rose11.prepdata_revised %>% na.omit, aes(x = CONTBEH, y = angle, fill = CONTBEH)) +
  geom_boxplot(show.legend = F) + ggtitle("Roseate")

angle_per_species_2011 = grid.arrange(arcticplot_angle,commplot_angle,sandplot_angle, roseplot_angle, nrow = 2 , ncol = 2, name = "Angle values per Behaviour", top = "Turning angles")
```

```{r summarised step plot}
grid.arrange(step_per_species_2011,angle_per_species_2011, ncol =2, top = "Movement Characteristics by species and continuous behaviour" )
```
#### Confusion Matrices

```{r summarised confusion matrices}
grid.arrange(heat_arctic,heat_sand,heat_common,heat_rose, ncol = 2, nrow = 2, top = "Confusion Matrices per Species")
```
# Mapping 

\ 
In the mapping section, the relevant plots will be produced and functions will be defined./

```{r initialise mapping Coordinates}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Resources for Mapping")
uk<-readOGR("GBR_adm1.shp") 
ukgrid <- "+init=epsg:27700" 
uk_ukgrid <- spTransform(uk, ukgrid)
```

```{r map per ID}
ggplot() +
geom_polygon(data = uk_ukgrid, aes(x = long, y = lat, group = group), colour = "black", fill = NA) +
geom_point(data=arc11.prepdata_revised %>% filter(ID == 59), aes(x=BNGX,y=BNGY, color = CONTBEH))+coord_fixed(ratio = 1, xlim = c(425000,430000+5000), ylim = c(600000, 600000+10000) )
```

```{r plotcomplete function}
plotcomplete = function(df, complete = 1, str = "Title", legendshow = F, viterbi = F){
  #
  #
  # Function that plots behavioural tracks of all birds based on complete/incomplete status
  #
  #### Inputs:
  #
  # df: dataframe from which coordinates will be extracted
  # complete:  1 for complete tracking, 0 for incomplete
  # str: string to be used in title
  # legendshow: whether to show legend or not
  # viterbi: colors provided by T: viterbi states / F = CONTBEH states
  #
  #### Output:
  #
  # ggplot tracks per tern, categorised by continuous behavior
  
    
  if (viterbi == T) {
  
  ggplot() +
      #Initialise map of area
  geom_polygon(data = uk_ukgrid, aes(x = long, y = lat, group = group), colour = "black", fill = NA) +
      # points in map
  geom_point(data=df %>% filter(Complete == complete),show.legend = legendshow, 
             aes(x=BNGX,y=BNGY, color = viterbi) )  +
      # Fix plot coordinates
      coord_fixed(ratio = 1.5, 
                      xlim = c(df %>% filter(Complete == complete) %>% pull(BNGX) %>% min() - 
                                df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() ,
                               df %>% filter(Complete == complete) %>% pull(BNGX) %>% max()) +
                               df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() , 
                      ylim = c(df %>% filter(Complete == complete) %>% pull(BNGY) %>% min() - 
                               df%>% filter(Complete == complete) %>% pull(BNGY) %>% sd(), 
                               df %>% filter(Complete == complete) %>% pull(BNGY) %>% max()) + 
                               df %>% filter(Complete == complete) %>% pull(BNGY) %>% sd() 
                      )  +
      ggtitle(str) +
      theme(legend.position = "bottom")
} else { 
  
  ggplot() +
      #Initialise map of area
  geom_polygon(data = uk_ukgrid, aes(x = long, y = lat, group = group), colour = "black", fill = NA) +
      # points in map
  geom_point(data=df %>% filter(Complete == complete),show.legend = legendshow, 
             aes(x=BNGX,y=BNGY, color = CONTBEH) )  +
      # Fix plot coordinates
      coord_fixed(ratio = 1.5, 
                      xlim = c(df %>% filter(Complete == complete) %>% pull(BNGX) %>% min() - 
                                df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() ,
                               df %>% filter(Complete == complete) %>% pull(BNGX) %>% max()) +
                               df %>% filter(Complete == complete) %>% pull(BNGX) %>% sd() , 
                      ylim = c(df %>% filter(Complete == complete) %>% pull(BNGY) %>% min() - 
                               df%>% filter(Complete == complete) %>% pull(BNGY) %>% sd(), 
                               df %>% filter(Complete == complete) %>% pull(BNGY) %>% max()) + 
                               df %>% filter(Complete == complete) %>% pull(BNGY) %>% sd() 
                      )  +
      ggtitle(str) +
      theme(legend.position = "bottom")
  }
}
```

```{r plotboth function}
plotcomplete_incomplete = function(df, title = "Title", legendshow = T, viterbi = F){
  #
  #
  # Plots both states by using the function "plotcomplete". 
  # 
  # Inputs: 
  # df: dataframe
  # title: string for title
  # legendshow: whether any legend will be printed
  # viterbi: passed on to the plotcomplete function
  #
  # Returns a grid-plot with both Complete-Incomplete plots combined
  
  df_com = suppressMessages(plotcomplete(df, str = "Complete", complete = 1, legendshow = F, viterbi = viterbi))
  df_incom = suppressMessages(plotcomplete(df, str = "Incomplete", complete = 0, legendshow = legendshow, viterbi = viterbi))
  grid = grid.arrange(df_com, df_incom, ncol = 2, top = title)
  return(grid)
}
```

```{r plotalltracks}
plotalltracks = function(df_arctic, df_sand, df_common, df_rose, legendshow_final = T, viterbi_par = F){
  
  #
  # Takes 4 dataframes as input (1 per species) and returns the 
  # corresponding grids by using the function "plotcomplete_incomplete"
  #
  # # Inputs:
  # df_arctic,..., df_rose = dataframes per species
  # legendshow_final = whether the last gridplot will have a legend or not
  # viterbi_par = F : actual CONBTEH - Coordinate track observations will be plotted
  #               T : viterbi state 1 states will be visually evalueated against "AS" true states
  # # Outputs
  # viterbi_par sets the output which will be either tern track plots of observed behaviours (F) or
  # "predicted" state 1-"AS" (T)
  #
  
  
  if (viterbi_par == F){
    
    grid1 = plotcomplete_incomplete(df_arctic, title = "Arctic", legendshow = F, viterbi = viterbi_par)
    grid2 = plotcomplete_incomplete(df_sand, title = "Sandwich", legendshow = F, viterbi = viterbi_par)
    grid3 = plotcomplete_incomplete(df_common, title = "Common", legendshow = F, viterbi = viterbi_par)
    grid4 = plotcomplete_incomplete(df_rose, title = "Roseate", legendshow = legendshow_final, viterbi = viterbi)
  
    } else {
    
    title1 = "Viterbi"
    title2 = "Observed"
    
    
    grid1_v = plotcomplete_incomplete(df_arctic %>% filter(viterbi==1), title = title1, legendshow = F, viterbi = T)
    grid1_o = plotcomplete_incomplete(df_arctic %>% filter(CONTBEH=="AS"), title = title2, legendshow = F, viterbi = F)
    grid.arrange(grid1_v,grid1_o, nrow = 2, left = "Arctic Foraging Locations")  
    
    grid1_v = plotcomplete_incomplete(df_sand %>% filter(viterbi==1), title = title1, legendshow = F, viterbi = T)
    grid1_o = plotcomplete_incomplete(df_sand %>% filter(CONTBEH=="AS"), title = title2, legendshow = F, viterbi = F)
    grid.arrange(grid1_v,grid1_o, ncol = 2, left = "Sandiwch Foraging Locations")
    
    grid1_v = plotcomplete_incomplete(df_common %>% filter(viterbi==1), title = title1, legendshow = F, viterbi = T)
    grid1_o = plotcomplete_incomplete(df_common %>% filter(CONTBEH=="AS"), title = title2, legendshow = F, viterbi = F)
    grid.arrange(grid1_v,grid1_o, ncol = 2, left = "Common Foraging Locations")
    
    grid1_v = plotcomplete_incomplete(df_rose %>% filter(viterbi==1), title = title1, legendshow = F, viterbi = T)
    grid1_o = plotcomplete_incomplete(df_rose %>% filter(CONTBEH=="AS"), title = title2, legendshow = F, viterbi = F)
    grid.arrange(grid1_v,grid1_o, ncol = 2, left = "Roseate Foraging Locations")
  }
  
}
```
```{r call plot all tracks function - used in mapping states}
plotalltracks(arc11.prepdata_revised, sand11.prepdata_revised,comm11.prepdata_revised,rose11.prepdata_revised)
```

```{r set viterbi columns }
arc11.prepdata_revised$viterbi = viterbi(arc11_revised_m)
sand11.prepdata_revised$viterbi = viterbi(sand_fit_m)
rose11.prepdata_revised$viterbi = viterbi(rose_fit_m)
comm11.prepdata_revised$viterbi = viterbi(common_fit_m)
```

```{r compare viterbi foraging ares with true ones}
plotalltracks(arc11.prepdata_revised, sand11.prepdata_revised,comm11.prepdata_revised,rose11.prepdata_revised, viterbi_par = T)
```


