---
title: "Dissertation HMM"
output: html_document
---

```{r setup, include=TRUE}
#Loaded Libraries
library(tidyverse)
library(readxl)
library(MASS)
library(moveHMM)  
library(caret)    # make conf.matrices
library(parallel) # parallel computing
library(ggplot2)  # data visualisation
```

### Load Data

The column types are set accordingly, while others are skipped.

```{r load data}
setwd("C:/Users/mikep/OneDrive/Documents/University of Edinburgh/Dissertations/HMM Seabirds/Data")


# Read Chick rearing excel file 2011

chk11 = read_excel("Coquet_2011_chickrearing_Tern_Tracks.xlsx", sheet = 1,
                   col_types = c("date", # Date column
                                 "skip", # skip colony
                                 "text", # Species column
                                 "numeric", # Track ID
                                 "skip","skip","skip", # skip HR MIN SEC
                                 "numeric","text",     # TSECS & CONTBEH
                                 "skip","skip",  # INSTANTBEH, FORAGESUC,
                                 "skip","skip", # PREYSIZE, PREYSPECIES
                                 "skip","skip",   # PREYFATE, NOTES
                                 "numeric","numeric", # BGNX, BGNY
                                 "numeric", "numeric", # LATITUDE, LONGITUDE
                                 "numeric","numeric", #DISTKM, DIST2COL
                                 "numeric","numeric" # BRG2COL, COMPLETE
                                 )
)

# turn contbeh to factor 
chk11$CONTBEH = as.factor(chk11$CONTBEH)

# rename TRACKID to ID
chk11 = chk11 %>%
  rename(
    ID = TRACKID
  )

#chk11 = chk11[order(chk11$ID,chk11$DATE,chk11$TSECS),]
```

```{r select libraries}
# copy dataset

chk11_cl = chk11 #%>%
    #dplyr:: select(DATE,SPECIES,TRACKID,TSECS,CONTBEH,BNGX,BNGY,LATITUDE,LONGITUDE,DISTKM,DIST2COL,BRG2COL,Complete)

# Save species names
speciesnames = unique(chk11_cl$SPECIES)
```
\
We will split the initial dataframe to sub-datasets per species. A function
is defined below that serves this specific reason.\ 
```{r function get_df}
get_df = function(df, species){
  
  ## Input:
  
  # df: dataframe to be filtered
  # species: species to be subsetted from df
  
  ## Output:
  
  # new_df: new dataframe containing examined species 
  
  species = enquo(species)
  
  # Simple function to extract species 
    new_df = df %>%
            filter(SPECIES == !!species) %>%
            dplyr::select(-SPECIES)
    
    return(as.data.frame(new_df))
}
```

```{r get dfs by species}
# dataframe by species - 2011 chickrearing

chk11.arc = get_df(chk11_cl,speciesnames[1]) # arctic

chk11.sand = get_df(chk11_cl,speciesnames[2]) # sandwich

chk11.comm = get_df(chk11_cl, speciesnames[3]) # common

chk11.comm.arc = get_df(chk11_cl, speciesnames[4]) # unsure (will not be used in the analysis)

chk11.rose = get_df(chk11_cl, speciesnames[5]) # roseate
```


### Arctic
\
#### Models and Plots
```{r prepData arctic}
arc11.prepdata = prepData(chk11.arc, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r revise prpData}
# Removes End and End continuous statuses from prepData object

revise = function(df){
  
  new_df = df %>%
    filter(df$CONTBEH != "END" & df$CONTBEH != "End")
  
  return(new_df)
}
```

```{r prepData arctic revised}
arc11.prepdata_revised =  revise(arc11.prepdata)

# Ensure that function worked as intented
unique(arc11.prepdata_revised$CONTBEH)
```
\
The histograms will be evaluated in order to define starting values. It seems that the histograms for the revised do not differ much (only 49 values were removed in the arctic 2011 case). Therefore picking similar starting values for both fitHMM instances is expected to produce the same optimization result. \
```{r plot prepdata differences}
#Check differences between dataframes -step
par(mfrow= c(2,2))
hist(arc11.prepdata$step, breaks = seq(0,0.019, l = 30), xlab = "Step" , main = "Original Dataframe")
hist(arc11.prepdata_revised$step, breaks = seq(0,0.019, l = 30), xlab = "Step", main = "End status removed")


hist(arc11.prepdata$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
hist(arc11.prepdata_revised$angle, breaks = seq(-pi,pi,length =50), xlab = "Angle", main = "")
```
It is apparent that removing End & END continuous behaviours plays no major role in the analysis.

\
Basic model fitting using whole dataset.\

```{r fit basic}
# 4 States for HMM
nbStates = 2

# default Initial Values for distributions
beta0 = NULL
delta0 = NULL

formula = ~1

# Distributions used
stepDist = "gamma"
angleDist = "vm"

angleMean = NULL
stationary = FALSE

# propotion of zero steps. To be used for mass at 0    
zerostepprop = length(which(arc11.prepdata == 0))/nrow(arc11.prepdata) # = 0.6139

mu0 = c(0.003,0.015)
sigma0 = c(0.005,0.005)
zeromass0 = c(zerostepprop,0.1)
stepPar0 = c(mu0, sigma0, zeromass0)

angleMean0 = c(0,0)
kappa0 = c(1,1)
anglePar0 = c(angleMean0,kappa0)

arc11_basic_m = fitHMM(data = arc11.prepdata, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot basic}
#par(mfrow = c(1,2))
plot(arc11_basic_m, plotCI = TRUE, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
Fitting on a revised dataset, with "End" and "END" states being removed.\

```{r fit revised}
# Fitting with no END and End
arc11_revised_m = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```

```{r plot revised}
plot(arc11_revised_m,plotCI = T, plotTracks = FALSE)#, breaks = seq(0,0.019,l=60))
```
\
It has been concluded that adding more variables worsens model performance. Fitted states seem less sensible as well by using this model.\
```{r fit additional models}
disthmm = fitHMM(data = arc11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = ~ DIST2COL + BRG2COL + DISTKM + TSECS)
```
\
```{r plot additional models}
plot(disthmm, plotTracks = F)
```

\ 
The AIC values will ensure that we have chosen the correct model (~1) for the analysis. As it will be shown later by the confusion matrices, the accurracy percentages between the whole and revised prepData objects will be close.\
\
```{r AIC}
AIC(arc11_basic_m, arc11_revised_m, disthmm)
```
\
The following function helps with running multiple iterations of the maximization process with randomized initial values. The likelihood will be evaluated to ensure model has converged. The "parallel" package is also used and will assist by providing a lower computation time. \
\
```{r fit experiment function}

fit_experiment = function(str_obj,obj){


#Inputs:
#     str_obj : string name of dataframe we want to fit
#     obj: prepData actual object of dataframe we want to fit

#Output:
#     model_parallel: list of 5 fitted models

  
#Seed set outside iteration for reproducible results
set.seed(1)

# 5 iterations of the maximisation process will be used
n_iter = 5

ncores = detectCores() - 1
cl = makeCluster(getOption("cl.cores",ncores))

clusterExport(cl, list(str_obj,"fitHMM"))

allPar0 = lapply(as.list(1:n_iter), function(x){
  
  
   stepMean0 = runif(2,
                    min = c(0.002,0.008),
                    max = c(0.005,0.015)
  )
  stepSD0 = runif(2,
                    min = c(0.001,0.001),
                    max = c(0.001,0.003)
  )
  angleMean0 = c(0,0)
  angleConc0 = runif(2,
                    min = c(0.05,1),
                    max = c(0.5,2)
  )
  
  steppar0_f = c(stepMean0, stepSD0,zeromass0)
  anglePar0_f = c(angleMean0,angleConc0)
    
  return(list(step = steppar0_f, angle = anglePar0_f))
})

# parallel computing
model_parallel = parLapply(cl = cl, X = allPar0, fun = function(par0) {

     m <- fitHMM(data = obj, nbStates = 2, stepPar0 = par0$step,
anglePar0 = par0$angle)

    return(m)
              }
    )


return(model_parallel)
}
```
\
Call function.
\
```{r parallel arcic}
arctic_parallel_m = fit_experiment("arc11.prepdata_revised", arc11.prepdata_revised)
```

\
All values depict the same likelihood for ~1 function. Therefore the likelihood has been maximised adequately.
```{r print likelihoods arctic}
unlist(lapply(arctic_parallel_m, function(m) m$mod$minimum))
```

#### Confusion Matrices
\
As shown by the histograms below, Transit Search (TS) along with direct flight (DF) are described by higher flight speed and low turns, something that is captured by State 2. On the other hand, Active search (AS) is quite the opposite and will be recoded as state 1. The confusion matrices are given below for all models.\
```{r 2 states histogram}
par(mfrow = c(2,2))
hist(arc11.prepdata_revised$step[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,breaks = 55 , xlab = "Step", main = "Arctic - TS & DF")
hist(arc11.prepdata_revised$step[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,breaks = 55 , xlab = "Step", main = "Arctic - AS")
hist(arc11.prepdata_revised$angle[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = "")
hist(arc11.prepdata_revised$angle[which((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==1)] ,seq(-pi,pi,l = 60) , xlab = "Angle", main = "")
```

```{r confusion matrix function}
confmatrx = function(model, model_data){
  
  # Function that saves model states,
  # transforms model data and prints caret
  # elements
  
  ## Input:
  #
  # model: moveHMM object to be used in the viterbi function
  # data: actual observations for evaluation
  #
  # Output:
  #
  # confrevised: ConfusionMatrix object from the package caret

  states = viterbi(model) %>% as.factor
  recoded = model_data$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor()

  confrevised = caret:: confusionMatrix(states,recoded)

return(confrevised)
}
```
\
A custom function will be implemented to create heatmaps from each confusion matrix.\
\

```{r heatmap function}

heat_map_custom = function(matrixobject,str){
  
  
  # Custom function that plots heatmaps and prints frequencies.
  ## Inputs: 
  # 
  # matrixobject: caret object from which table will be extracted
  # str: string to be used on title
  
  
ggplot(as.data.frame(matrixobject$table), aes(x=Reference,y=Prediction, fill = Freq/sum(Freq))) + geom_tile() + theme_bw() +
    ggtitle(paste("Confusion Matrix for",str))+
   scale_fill_distiller(palette = "Greens") + 
   geom_text(aes(label= paste(100*round(Freq/sum(Freq),4),"%"))) + 
    guides(fill = guide_legend(title = "Accurracy"))+
    # Print acurracy of model extracted by matrix object
    annotate("text", x=0.7,y =0.2, label = paste("Overall Acurracy:", 100*as.numeric(round(matrixobject$overall[1],4)),"%" ))+
    coord_cartesian(ylim = c(1,2),clip="off")
}
```

```{r confusion matrix revised}
conf_arct_revised = confmatrx(arc11_revised_m,arc11.prepdata_revised)
conf_arct_revised
```
\ 
```{r plot heatmap for revised model}
heat_map_custom(conf_arct_revised,"Arctic chickrearing - 2011")
```


```{r experiment}
hist(arc11.prepdata_revised$step[which((viterbi(arc11_revised_m)) !=  ((arc11.prepdata_revised$CONTBEH %>%
         recode("TS" = 2, "AS" = 1, "DF" = 2) %>%
         as.factor())==2))], breaks = 60)

```



The additional variables produce higher accuracy but also fail to adequately predict type 1 cases. The analysis indicates that ~1 produces the best model.\
```{r conf matrix additional}
conf_arc_add = confmatrx(disthmm, arc11.prepdata_revised)

heat_map_custom(conf_arc_add, "Arctic 2011 -Additional Models")
```

```{r test}
```

```{r slow version as comment}

#niter = 5
#model = list()

#for (i in 1:niter){
#  stepMean0 = runif(2,
#                    min = c(0.002,0.008),
#                    max = c(0.005,0.015)
#  )
#  stepSD0 = runif(2,
#                    min = c(0.001,0.001),
#                    max = c(0.001,0.003)
#  )
#  angleMean0 = c(0,0)
#  angleConc0 = runif(2,
#                    min = c(0.05,1),
#                    max = c(0.5,2)
#  )
#  
#  steppar0_rep = c(stepMean0, stepSD0,zeromass0)
#  anglePar0_rep = c(angleMean0,angleConc0)
#  
#  model[[i]] = fitHMM(data = arc11.prepdata, nbStates = nbStates, stepPar0 = steppar0_rep, anglePar0 = anglePar0_rep, formula = formula)
#  
#}
```

```{r new coordinates discarded}
#coord_arc = chk11



#coord_arc = coord_arc %>% 
#  mutate(new_latitude = deg(
           
#asin(
  
#sin(rad(LATITUDE))*cos(DISTKM/6378.1) +
                               #cos(rad(LATITUDE))*sin(DISTKM/6378.1)*BRG2COL
#     )
#),
#
#new_longitude = LONGITUDE + #atan2(sin(BRG2COL)*sin(DISTKM/6378.1)*cos(rad(LATITUDE)),
#      cos(DISTKM/6378.1)-sin(rad(LATITUDE))*sin(rad(new_latitu#de)))
  
#) %>%
#  as.data.frame()
```

```{r prepData coord new discarded}
# = prepData(coord_arc, type = "LL", coordNames = #c("new_longitude","new_latitude"))
```
```{r plot coord prepdata discarded}
#hist(coordprep$angle)
```

### Sandwich
\
The analysis will be the same as the previous section\
\
#### Data Manipulation

```{r sandwich prepdata}
sand11.prepdata = prepData(chk11.sand, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```
```{r sandwich plots and revised}
sand11.prepdata_revised = revise(sand11.prepdata)

# Remove outlier 

sand11.prepdata_revised = sand11.prepdata_revised[-which.max(sand11.prepdata_revised$step),]

par(mfrow=c(1,2))
hist(sand11.prepdata_revised$step, xlab = "Step")
hist(sand11.prepdata_revised$angle, xlab = "Angle")
```
\
#### Fit and Plots
As previously we will run a parallel experiment to evaluate convergence.\

```{r sand fit parallel}
sand_parallel_m = fit_experiment("sand11.prepdata_revised",sand11.prepdata_revised)
```

```{r print likelihoods sand}
# Print likelihoods
unlist(lapply(sand_parallel_m, function(m) m$mod$minimum))
```
\
Convergence is reached based on the above results.
```{r sand fit}
sand_fit_m = fitHMM(data = sand11.prepdata_revised, nbStates = nbStates, stepPar0 = stepPar0, anglePar0 = anglePar0, formula = formula)
```
\
```{r sand plot}
plot(sand_fit_m,  plotTracks = F)
```
#### Confusion Matrix

```{r sandwich confusion matrix}
conf_sand = confmatrx(sand_fit_m,sand11.prepdata_revised)

heat_map_custom(conf_sand, "sand11.prepdata_revised"
                )
```
### Common

#### Data Manipulation
```{r common prepdata}
comm11.prepdata = prepData(chk11.comm, type = "LL", coordNames = c("LONGITUDE","LATITUDE"))
```

```{r common revise & Plot}
comm11.prepdata_revised = revise(comm11.prepdata)

par(mfrow = c(1,2))
hist(comm11.prepdata_revised$step, seq(0,0.019,l=40))
hist(comm11.prepdata_revised$angle,seq(-pi,pi,l=40))
```
#### Fit and Plots
\

```{r common fit parallel}
common_parallel_m = fit_experiment("comm11.prepdata_revised",comm11.prepdata_revised)
```

```{r print likelihoods common}
# Print likelihoods
unlist(lapply(common_parallel_m, function(m) m$mod$minimum))
```
